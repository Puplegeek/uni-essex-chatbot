{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5cf23bd3-fb8f-4dbf-aa78-66efaee34504",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Extracted 8317 URLs.\n",
      "Saved main data to 'essex_content_sitemap_2nd_Prefix.csv'\n",
      "✅ Saved 39 URLs to essex_urls_about.csv\n",
      "✅ Saved 38 URLs to essex_urls_alumni.csv\n",
      "✅ Saved 2 URLs to essex_urls_apprenticeships.csv\n",
      "✅ Saved 5 URLs to essex_urls_arena.csv\n",
      "✅ Saved 13 URLs to essex_urls_blog.csv\n",
      "✅ Saved 45 URLs to essex_urls_business.csv\n",
      "✅ Saved 209 URLs to essex_urls_centres-and-institutes.csv\n",
      "✅ Saved 6 URLs to essex_urls_china.csv\n",
      "✅ Saved 6 URLs to essex_urls_choir.csv\n",
      "✅ Saved 7 URLs to essex_urls_clearing.csv\n",
      "✅ Saved 562 URLs to essex_urls_departments.csv\n",
      "✅ Saved 14 URLs to essex_urls_disclaimer.csv\n",
      "✅ Saved 9 URLs to essex_urls_donate.csv\n",
      "✅ Saved 15 URLs to essex_urls_event-series.csv\n",
      "✅ Saved 30 URLs to essex_urls_events.csv\n",
      "✅ Saved 1 URLs to essex_urls_fees-and-funding.csv\n",
      "✅ Saved 12 URLs to essex_urls_global.csv\n",
      "✅ Saved 49 URLs to essex_urls_governance-and-strategy.csv\n",
      "✅ Saved 14 URLs to essex_urls_graduation.csv\n",
      "✅ Saved 108 URLs to essex_urls_international.csv\n",
      "✅ Saved 16 URLs to essex_urls_jobs.csv\n",
      "✅ Saved 86 URLs to essex_urls_life.csv\n",
      "✅ Saved 2538 URLs to essex_urls_news.csv\n",
      "✅ Saved 2014 URLs to essex_urls_people.csv\n",
      "✅ Saved 62 URLs to essex_urls_postgraduate.csv\n",
      "✅ Saved 78 URLs to essex_urls_research.csv\n",
      "✅ Saved 363 URLs to essex_urls_research-projects.csv\n",
      "✅ Saved 60 URLs to essex_urls_scholarships.csv\n",
      "✅ Saved 44 URLs to essex_urls_schools-and-colleges.csv\n",
      "✅ Saved 91 URLs to essex_urls_short-courses.csv\n",
      "✅ Saved 55 URLs to essex_urls_sport.csv\n",
      "✅ Saved 1 URLs to essex_urls_sport-homepage-test.csv\n",
      "✅ Saved 936 URLs to essex_urls_staff.csv\n",
      "✅ Saved 677 URLs to essex_urls_student.csv\n",
      "✅ Saved 25 URLs to essex_urls_study-abroad.csv\n",
      "✅ Saved 1 URLs to essex_urls_study-online.csv\n",
      "✅ Saved 1 URLs to essex_urls_subjects.csv\n",
      "✅ Saved 12 URLs to essex_urls_sustainability.csv\n",
      "✅ Saved 20 URLs to essex_urls_test.csv\n",
      "✅ Saved 21 URLs to essex_urls_undergraduate.csv\n",
      "✅ Saved 11 URLs to essex_urls_visit-us.csv\n",
      "✅ Saved 17 URLs to essex_urls_welcome.csv\n",
      "✅ Saved 4 URLs to essex_urls_wivenhoe-park.csv\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import xml.etree.ElementTree as ET\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Sitemap URL\n",
    "sitemap_url = 'https://www.essex.ac.uk/content.xml'\n",
    "\n",
    "# Fetch and decode\n",
    "response = requests.get(sitemap_url)\n",
    "content = response.content.decode('utf-8', errors='replace')\n",
    "\n",
    "# Parse XML\n",
    "try:\n",
    "    root = ET.fromstring(content)\n",
    "    ns = {'ns': 'http://www.sitemaps.org/schemas/sitemap/0.9'}\n",
    "\n",
    "    # Extract URLs and lastmod\n",
    "    data = []\n",
    "    for url_elem in root.findall('ns:url', ns):\n",
    "        loc = url_elem.find('ns:loc', ns)\n",
    "        lastmod = url_elem.find('ns:lastmod', ns)\n",
    "        data.append({\n",
    "            'URL': loc.text if loc is not None else '',\n",
    "            'Last Modified': lastmod.text if lastmod is not None else ''\n",
    "        })\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "    print(f\"✅ Extracted {len(df)} URLs.\")\n",
    "    \n",
    "    # Extract the second path segment after the domain\n",
    "    df['Second Prefix'] = df['URL'].apply(lambda url: url.replace('https://www.essex.ac.uk/', '').split('/')[0])\n",
    "    \n",
    "    # Save the main CSV file with all data and new name\n",
    "    main_filename = \"essex_content_sitemap_2nd_Prefix.csv\"\n",
    "    df.to_csv(main_filename, index=False)\n",
    "    print(f\"Saved main data to '{main_filename}'\")\n",
    "    \n",
    "    # Group by 'Second Prefix' and save each group to a CSV\n",
    "    for prefix, group_df in df.groupby('Second Prefix'):\n",
    "        # Sanitize prefix to create a valid filename\n",
    "        safe_prefix = re.sub(r'[^a-zA-Z0-9_-]', '_', prefix)\n",
    "        filename = f\"essex_urls_{safe_prefix}.csv\"\n",
    "        group_df.to_csv(filename, index=False)\n",
    "        print(f\"✅ Saved {len(group_df)} URLs to {filename}\")\n",
    "\n",
    "except ET.ParseError as e:\n",
    "    print(\"❌ XML Parse Error:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f510f309-4d8c-424a-8d82-41b49bcd2c87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Hierarchical CSV created with columns:\n",
      "['Last Modified', 'URL', 'Level_1', 'Level_2', 'Level_3', 'Level_4', 'Level_5', 'Level_6', 'Level_7', 'Level_8']\n",
      "\n",
      "Sample output:\n",
      "  Last Modified                                           URL   Level_1  \\\n",
      "0    2022-11-07     https://www.essex.ac.uk/research/showcase  research   \n",
      "1    2023-04-13         https://www.essex.ac.uk/blog/post-map      blog   \n",
      "2    2023-11-10  https://www.essex.ac.uk/life/loughton-campus      life   \n",
      "\n",
      "           Level_2 Level_3 Level_4 Level_5 Level_6 Level_7 Level_8  \n",
      "0         showcase    <NA>    <NA>    <NA>    <NA>    <NA>    <NA>  \n",
      "1         post-map    <NA>    <NA>    <NA>    <NA>    <NA>    <NA>  \n",
      "2  loughton-campus    <NA>    <NA>    <NA>    <NA>    <NA>    <NA>  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "# Read existing CSV\n",
    "df = pd.read_csv(\"essex_content_sitemap_2nd_Prefix.csv\")\n",
    "\n",
    "# Extract path segments from URLs\n",
    "def get_hierarchy(url):\n",
    "    parsed = urlparse(url)\n",
    "    return [seg for seg in parsed.path.split('/') if seg]\n",
    "\n",
    "df['Path_Segments'] = df['URL'].apply(get_hierarchy)\n",
    "\n",
    "# Determine maximum depth needed\n",
    "max_depth = df['Path_Segments'].apply(len).max()\n",
    "\n",
    "# Create hierarchical columns\n",
    "for i in range(max_depth):\n",
    "    df[f'Level_{i+1}'] = df['Path_Segments'].apply(\n",
    "        lambda x: x[i] if i < len(x) else pd.NA\n",
    "    )\n",
    "\n",
    "# Create final dataframe with desired columns\n",
    "hierarchy_df = df[['Last Modified', 'URL'] + [f'Level_{i+1}' for i in range(max_depth)]]\n",
    "\n",
    "# Save to new CSV\n",
    "hierarchy_df.to_csv(\"essex_url_hierarchy_with_dates.csv\", index=False)\n",
    "\n",
    "print(\"✅ Hierarchical CSV created with columns:\")\n",
    "print(hierarchy_df.columns.tolist())\n",
    "print(f\"\\nSample output:\\n{hierarchy_df.head(3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0401b1e-4409-4ab6-bc77-c7beac44075a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
