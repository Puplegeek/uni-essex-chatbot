import requests
import xml.etree.ElementTree as ET
import pandas as pd
import re

# Sitemap URL
sitemap_url = 'https://www.essex.ac.uk/content.xml'

# Fetch and decode
response = requests.get(sitemap_url)
content = response.content.decode('utf-8', errors='replace')

# Parse XML
try:
    root = ET.fromstring(content)
    ns = {'ns': 'http://www.sitemaps.org/schemas/sitemap/0.9'}

    # Extract URLs and lastmod
    data = []
    for url_elem in root.findall('ns:url', ns):
        loc = url_elem.find('ns:loc', ns)
        lastmod = url_elem.find('ns:lastmod', ns)
        data.append({
            'URL': loc.text if loc is not None else '',
            'Last Modified': lastmod.text if lastmod is not None else ''
        })

    df = pd.DataFrame(data)
    print(f"✅ Extracted {len(df)} URLs.")
    
    # Extract the second path segment after the domain
    df['Second Prefix'] = df['URL'].apply(lambda url: url.replace('https://www.essex.ac.uk/', '').split('/')[0])
    
    # Save the main CSV file with all data and new name
    main_filename = "essex_content_sitemap_2nd_Prefix.csv"
    df.to_csv(main_filename, index=False)
    print(f"Saved main data to '{main_filename}'")
    
    # Group by 'Second Prefix' and save each group to a CSV
    for prefix, group_df in df.groupby('Second Prefix'):
        # Sanitize prefix to create a valid filename
        safe_prefix = re.sub(r'[^a-zA-Z0-9_-]', '_', prefix)
        filename = f"essex_urls_{safe_prefix}.csv"
        group_df.to_csv(filename, index=False)
        print(f"✅ Saved {len(group_df)} URLs to {filename}")

except ET.ParseError as e:
    print("❌ XML Parse Error:", e)


import pandas as pd
from urllib.parse import urlparse

# Read existing CSV
df = pd.read_csv("essex_content_sitemap_2nd_Prefix.csv")

# Extract path segments from URLs
def get_hierarchy(url):
    parsed = urlparse(url)
    return [seg for seg in parsed.path.split('/') if seg]

df['Path_Segments'] = df['URL'].apply(get_hierarchy)

# Determine maximum depth needed
max_depth = df['Path_Segments'].apply(len).max()

# Create hierarchical columns
for i in range(max_depth):
    df[f'Level_{i+1}'] = df['Path_Segments'].apply(
        lambda x: x[i] if i < len(x) else pd.NA
    )

# Create final dataframe with desired columns
hierarchy_df = df[['Last Modified', 'URL'] + [f'Level_{i+1}' for i in range(max_depth)]]

# Save to new CSV
hierarchy_df.to_csv("essex_url_hierarchy_with_dates.csv", index=False)

print("✅ Hierarchical CSV created with columns:")
print(hierarchy_df.columns.tolist())
print(f"\nSample output:\n{hierarchy_df.head(3)}")



